"""
Heatmap Training Script for Wan2.2
åŸºäºåŸå§‹train.pyï¼Œä¸“é—¨ç”¨äºçƒ­åŠ›å›¾åºåˆ—ç”Ÿæˆè®­ç»ƒ
"""

import torch
import os
import json
import sys
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

# è®¾ç½®CoppeliaSimç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨å…¶ä»–å¯¼å…¥ä¹‹å‰ï¼‰
os.environ["COPPELIASIM_ROOT"] = "/share/project/lpy/BridgeVLA/finetune/CoppeliaSim_Edu_V4_1_0_Ubuntu20_04"
os.environ["LD_LIBRARY_PATH"] = os.environ.get("LD_LIBRARY_PATH", "") + ":" + os.environ["COPPELIASIM_ROOT"]
os.environ["QT_QPA_PLATFORM_PLUGIN_PATH"] = os.environ["COPPELIASIM_ROOT"]
os.environ["DISPLAY"] = ":1.0"

# SwanLabå¯¼å…¥ï¼ˆå¯é€‰ï¼‰
try:
    import swanlab
    SWANLAB_AVAILABLE = True
except ImportError:
    SWANLAB_AVAILABLE = False
    print("Warning: SwanLab not available. Install with: pip install swanlab")

from diffsynth import load_state_dict
from diffsynth.pipelines.wan_video_new import WanVideoPipeline, ModelConfig
from diffsynth.trainers.utils import DiffusionTrainingModule, ModelLogger, launch_training_task, wan_parser
from accelerate import Accelerator
from accelerate.utils import DistributedDataParallelKwargs
from tqdm import tqdm
import torch.utils.data

# æ·»åŠ trainersè·¯å¾„ä»¥å¯¼å…¥æˆ‘ä»¬çš„è‡ªå®šä¹‰æ•°æ®é›†
sys.path.append(os.path.join(os.path.dirname(__file__), "../../../"))
from diffsynth.trainers.heatmap_dataset import HeatmapDatasetFactory

os.environ["TOKENIZERS_PARALLELISM"] = "false"


class HeatmapWanTrainingModule(DiffusionTrainingModule):
    """
    çƒ­åŠ›å›¾ä¸“ç”¨çš„Wanè®­ç»ƒæ¨¡å—
    ç»§æ‰¿åŸå§‹WanTrainingModuleï¼Œé’ˆå¯¹çƒ­åŠ›å›¾åºåˆ—ç”Ÿæˆè¿›è¡Œä¼˜åŒ–
    """

    def __init__(
        self,
        model_paths=None, model_id_with_origin_paths=None,
        trainable_models=None,
        lora_base_model=None, lora_target_modules="q,k,v,o,ffn.0,ffn.2", lora_rank=32, lora_checkpoint=None,
        use_gradient_checkpointing=True,
        use_gradient_checkpointing_offload=False,
        extra_inputs=None,
        max_timestep_boundary=1.0,
        min_timestep_boundary=0.0,
    ):
        super().__init__()
        # Load models
        model_configs = self.parse_model_configs(model_paths, model_id_with_origin_paths, enable_fp8_training=False)
        self.pipe = WanVideoPipeline.from_pretrained(torch_dtype=torch.bfloat16, device="cuda", model_configs=model_configs)

        # Training mode
        self.switch_pipe_to_training_mode(
            self.pipe, trainable_models,
            lora_base_model, lora_target_modules, lora_rank, lora_checkpoint=lora_checkpoint,
            enable_fp8_training=False,
        )

        # Store other configs
        self.use_gradient_checkpointing = use_gradient_checkpointing
        self.use_gradient_checkpointing_offload = use_gradient_checkpointing_offload
        self.extra_inputs = extra_inputs.split(",") if extra_inputs is not None else []
        self.max_timestep_boundary = max_timestep_boundary
        self.min_timestep_boundary = min_timestep_boundary

        # Debug settings
        self.debug_counter = 0
        self.debug_save_dir = "/share/project/lpy/BridgeVLA/Wan/DiffSynth-Studio/debug_log"


    def forward_preprocess(self, data):
        """
        é¢„å¤„ç†è¾“å…¥æ•°æ®ï¼Œä¸“é—¨é’ˆå¯¹çƒ­åŠ›å›¾æ•°æ®æ ¼å¼
        """
        # CFG-sensitive parameters
        inputs_posi = {"prompt": data["prompt"]}
        inputs_nega = {}

        # CFG-unsensitive parameters
        inputs_shared = {
            # çƒ­åŠ›å›¾åºåˆ—ä½œä¸ºè§†é¢‘è¾“å…¥
            "input_video": data["video"],
            "height": data["video"][0].size[1],
            "width": data["video"][0].size[0],
            "num_frames": len(data["video"]),
            # è®­ç»ƒç›¸å…³å‚æ•°
            "cfg_scale": 1,
            "tiled": False,
            "rand_device": self.pipe.device,
            "use_gradient_checkpointing": self.use_gradient_checkpointing,
            "use_gradient_checkpointing_offload": self.use_gradient_checkpointing_offload,
            "cfg_merge": False,
            "vace_scale": 1,
            "max_timestep_boundary": self.max_timestep_boundary,
            "min_timestep_boundary": self.min_timestep_boundary,
        }

        # Extra inputs - å¯¹äºçƒ­åŠ›å›¾ä»»åŠ¡ï¼Œä¸»è¦æ˜¯input_image
        for extra_input in self.extra_inputs:
            if extra_input == "input_image":
                # ä½¿ç”¨é¦–å¸§RGBå›¾åƒä½œä¸ºæ¡ä»¶è¾“å…¥
                inputs_shared["input_image"] = data["input_image"]
            elif extra_input == "end_image":
                inputs_shared["end_image"] = data["video"][-1]
            elif extra_input == "reference_image" or extra_input == "vace_reference_image":
                inputs_shared[extra_input] = data[extra_input][0]
            else:
                if extra_input in data:
                    inputs_shared[extra_input] = data[extra_input]

        # Pipeline units will automatically process the input parameters.
        for unit in self.pipe.units:
            inputs_shared, inputs_posi, inputs_nega = self.pipe.unit_runner(unit, self.pipe, inputs_shared, inputs_posi, inputs_nega)
        return {**inputs_shared, **inputs_posi}


    def visualize_processed_inputs(self, inputs, data):
        """
        å¯è§†åŒ–ç»è¿‡forward_preprocesså¤„ç†åçš„input_videoå’Œinput_image
        """
        try:
            # ç¡®ä¿debugç›®å½•å­˜åœ¨
            os.makedirs(self.debug_save_dir, exist_ok=True)

            print(f"\n=== DEBUG VISUALIZATION (Counter: {self.debug_counter}) ===")
            print(f"Original prompt: {data.get('prompt', 'N/A')}")
            print(f"Processed inputs keys: {list(inputs.keys())}")

            # å¯è§†åŒ–processed input_image
            if 'input_image' in inputs and inputs['input_image'] is not None:
                input_img = inputs['input_image']
                if hasattr(input_img, 'save'):  # PIL Image
                    input_img_path = os.path.join(self.debug_save_dir, f"debug_{self.debug_counter:04d}_processed_input_image.png")
                    input_img.save(input_img_path)
                    print(f"Processed input image saved: {input_img_path}")
                    print(f"Processed input image size: {input_img.size}")
                else:
                    print(f"Input image type: {type(input_img)}, shape: {getattr(input_img, 'shape', 'N/A')}")

            # å¯è§†åŒ–processed input_video
            if 'input_video' in inputs and inputs['input_video'] is not None:
                input_video = inputs['input_video']

                if isinstance(input_video, list) and len(input_video) > 0:
                    # å¦‚æœæ˜¯PILå›¾åƒåˆ—è¡¨
                    video_frames = input_video
                    num_frames = len(video_frames)

                    print(f"Processed video frames count: {num_frames}")

                    # åˆ›å»ºç½‘æ ¼æ˜¾ç¤ºæ‰€æœ‰å¸§
                    cols = min(5, num_frames)  # æœ€å¤š5åˆ—
                    rows = (num_frames + cols - 1) // cols

                    fig, axes = plt.subplots(rows, cols, figsize=(15, 3*rows))
                    if rows == 1 and cols == 1:
                        axes = [axes]
                    elif rows == 1 or cols == 1:
                        axes = axes.flatten()
                    else:
                        axes = axes.flatten()

                    for i, frame in enumerate(video_frames):
                        if i < len(axes):
                            # å°†PILå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
                            if hasattr(frame, 'save'):  # PIL Image
                                frame_array = np.array(frame)
                                axes[i].imshow(frame_array)
                                axes[i].set_title(f"Processed Frame {i}")
                                axes[i].axis('off')

                                # åŒæ—¶ä¿å­˜å•ç‹¬çš„å¸§
                                frame_path = os.path.join(self.debug_save_dir, f"debug_{self.debug_counter:04d}_processed_frame_{i:02d}.png")
                                frame.save(frame_path)
                            else:
                                axes[i].text(0.5, 0.5, f"Frame {i}\n{type(frame)}",
                                           ha='center', va='center', transform=axes[i].transAxes)
                                axes[i].axis('off')

                    # éšè—å¤šä½™çš„å­å›¾
                    for i in range(num_frames, len(axes)):
                        axes[i].axis('off')

                    # ä¿å­˜ç»„åˆå›¾
                    combined_path = os.path.join(self.debug_save_dir, f"debug_{self.debug_counter:04d}_processed_video_sequence.png")
                    plt.tight_layout()
                    plt.savefig(combined_path, dpi=150, bbox_inches='tight')
                    plt.close()

                    print(f"Processed video sequence saved: {combined_path}")
                    print(f"Individual processed frames saved with pattern: debug_{self.debug_counter:04d}_processed_frame_XX.png")

                    if len(video_frames) > 0 and hasattr(video_frames[0], 'size'):
                        print(f"Processed video info: {num_frames} frames, size: {video_frames[0].size}")
                else:
                    print(f"Input video type: {type(input_video)}, shape: {getattr(input_video, 'shape', 'N/A')}")

            # æ‰“å°å…¶ä»–é‡è¦çš„inputsä¿¡æ¯
            for key, value in inputs.items():
                if key not in ['input_image', 'input_video']:
                    if isinstance(value, (int, float, str, bool)):
                        print(f"  {key}: {value}")
                    elif hasattr(value, 'shape'):
                        print(f"  {key}: shape {value.shape}, dtype {getattr(value, 'dtype', 'N/A')}")
                    elif isinstance(value, (list, tuple)):
                        print(f"  {key}: {type(value)} of length {len(value)}")
                    else:
                        print(f"  {key}: {type(value)}")

            print(f"=== END DEBUG VISUALIZATION ===")

        except Exception as e:
            print(f"Error in debug visualization: {e}")
            import traceback
            traceback.print_exc()

    def forward(self, data, inputs=None):
        """
        å‰å‘ä¼ æ’­ï¼Œè®¡ç®—æŸå¤±
        """
        # é¢„å¤„ç†
        if inputs is None:
            inputs = self.forward_preprocess(data)

        # HARDCODED DEBUGåˆ†æ”¯ - æ‰‹åŠ¨è®¾ç½®ä¸ºTrueæ—¶å¯ç”¨å¯è§†åŒ–
        DEBUG_VISUALIZATION = False  # æ‰‹åŠ¨ä¿®æ”¹æ­¤å¤„ä¸ºTrueæ¥å¯ç”¨debugå¯è§†åŒ–

        if DEBUG_VISUALIZATION:
            print(f"\nğŸ” DEBUG MODE ACTIVATED (Step {self.debug_counter})")
            self.visualize_processed_inputs(inputs, data)
            self.debug_counter += 1

        # æ­£å¸¸å‰å‘ä¼ æ’­
        models = {name: getattr(self.pipe, name) for name in self.pipe.in_iteration_models}
        loss = self.pipe.training_loss(**models, **inputs)
        return loss

    def log_to_swanlab(self, loss_value, step, swanlab_run=None):
        """
        è®°å½•æŸå¤±åˆ°SwanLab
        """
        if swanlab_run is not None and SWANLAB_AVAILABLE:
            try:
                import swanlab
                # åªè®°å½•æœ‰æ•ˆçš„æ•°å€¼ï¼Œé¿å…Noneå€¼å¯¼è‡´çš„é”™è¯¯
                log_data = {
                    "train_loss": loss_value,
                    "step": step
                }

                # å¦‚æœæœ‰å­¦ä¹ ç‡æ–¹æ³•ä¸”è¿”å›æœ‰æ•ˆå€¼ï¼Œæ‰è®°å½•å­¦ä¹ ç‡
                if hasattr(self, 'get_current_lr'):
                    lr = self.get_current_lr()
                    if lr is not None:
                        log_data["learning_rate"] = lr

                swanlab.log(log_data, step=step)
                print(f"SwanLab logged: step={step}, loss={loss_value:.4f}")
            except Exception as e:
                print(f"Warning: Failed to log to SwanLab: {e}")
                import traceback
                traceback.print_exc()


def launch_optimized_training_task(
    dataset: torch.utils.data.Dataset,
    model: DiffusionTrainingModule,
    model_logger: ModelLogger,
    args=None,
    temp_accelerator=None,
):
    """
    ä¼˜åŒ–ç‰ˆæœ¬çš„è®­ç»ƒä»»åŠ¡å¯åŠ¨å™¨ï¼Œä¸“é—¨é’ˆå¯¹40GB A100è¿›è¡Œå†…å­˜å’Œæ€§èƒ½ä¼˜åŒ–
    """
    if args is None:
        raise ValueError("args is required for optimized training")

    # å‚æ•°æå–
    learning_rate = args.learning_rate
    weight_decay = args.weight_decay
    num_workers = args.dataset_num_workers
    save_steps = args.save_steps
    num_epochs = args.num_epochs
    gradient_accumulation_steps = args.gradient_accumulation_steps
    find_unused_parameters = args.find_unused_parameters
    train_batch_size = args.train_batch_size

    # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°é…ç½®ä¿¡æ¯ï¼ˆé¿å…å¤šè¿›ç¨‹é‡å¤æ‰“å°ï¼‰
    if temp_accelerator is None:
        temp_accelerator_for_check = Accelerator()
    else:
        temp_accelerator_for_check = temp_accelerator
    if temp_accelerator_for_check.is_main_process:
        print(f"Optimized training configuration:")
        print(f"  - Batch size: {train_batch_size}")
        print(f"  - Data workers: {num_workers}")
        print(f"  - Gradient accumulation: {gradient_accumulation_steps}")
        print(f"  - Gradient checkpointing offload: {args.use_gradient_checkpointing_offload}")

    # ä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨é…ç½®ï¼ˆå•è¿›ç¨‹æ¨¡å¼ï¼‰
    dataloader_kwargs = {
        'batch_size': train_batch_size,
        'shuffle': True,
        'num_workers': num_workers,
        'pin_memory': num_workers == 0,  # å•è¿›ç¨‹æ—¶å¯ç”¨pin memory
        'persistent_workers': num_workers > 0,  # åªåœ¨å¤šè¿›ç¨‹æ—¶å¯ç”¨
        'prefetch_factor': 2 if num_workers > 0 else None,  # åªåœ¨å¤šè¿›ç¨‹æ—¶é¢„å–
        'drop_last': True,  # ä¸¢å¼ƒæœ€åä¸å®Œæ•´çš„batch
        'collate_fn': lambda x: x[0],
    }

    if temp_accelerator_for_check.is_main_process:
        print(f"DataLoader configuration: {dataloader_kwargs}")

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    dataloader = torch.utils.data.DataLoader(dataset, **dataloader_kwargs)

    # ä¼˜åŒ–å™¨é…ç½®
    optimizer = torch.optim.AdamW(
        model.trainable_modules(),
        lr=learning_rate,
        weight_decay=weight_decay,
        eps=1e-6,  # ç¨å¾®æé«˜æ•°å€¼ç¨³å®šæ€§
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)

    # Acceleratoré…ç½®
    accelerator = Accelerator(
        gradient_accumulation_steps=gradient_accumulation_steps,
        kwargs_handlers=[DistributedDataParallelKwargs(find_unused_parameters=find_unused_parameters)],
    )

    # å‡†å¤‡è®­ç»ƒç»„ä»¶
    model, optimizer, dataloader, scheduler = accelerator.prepare(model, optimizer, dataloader, scheduler)

    # æ˜¾å­˜ä¼˜åŒ–ï¼šå¯ç”¨è‡ªåŠ¨æ¸…ç†æ— ç”¨å˜é‡
    if hasattr(torch.cuda, 'empty_cache'):
        torch.cuda.empty_cache()

    # è®­ç»ƒå¾ªç¯
    for epoch_id in range(num_epochs):
        model.train()
        epoch_loss = 0
        step_count = 0

        # æ·»åŠ è¿›åº¦æ¡
        pbar = tqdm(dataloader, desc=f"Epoch {epoch_id+1}/{num_epochs}")

        for step, data in enumerate(pbar):
            with accelerator.accumulate(model):
                optimizer.zero_grad(set_to_none=True)  # æ›´é«˜æ•ˆçš„æ¢¯åº¦æ¸…é›¶

                # å‰å‘ä¼ æ’­
                if dataset.load_from_cache:
                    loss = model({}, inputs=data)
                else:
                    loss = model(data)

                # åå‘ä¼ æ’­
                accelerator.backward(loss)

                # æ¢¯åº¦è£å‰ª
                if hasattr(args, 'max_grad_norm') and args.max_grad_norm > 0:
                    accelerator.clip_grad_norm_(model.parameters(), args.max_grad_norm)

                # ä¼˜åŒ–å™¨æ­¥éª¤
                optimizer.step()
                scheduler.step()

                # è®°å½•æŸå¤±
                epoch_loss += loss.item()
                step_count += 1

                # SwanLabæ—¥å¿—è®°å½• - åªåœ¨ä¸»è¿›ç¨‹ä¸”æ»¡è¶³logging_stepsé¢‘ç‡æ—¶è®°å½•
                global_step = step + epoch_id * len(dataloader)
                should_log = (accelerator.is_main_process and
                             hasattr(args, 'swanlab_run') and args.swanlab_run is not None and
                             hasattr(args, 'logging_steps') and global_step % args.logging_steps == 0)

                if should_log:
                    print(f"Logging to SwanLab at step {global_step}")
                    # è®°å½•è®­ç»ƒæŒ‡æ ‡åˆ°SwanLab
                    try:
                        import swanlab
                        # è·å–å½“å‰å­¦ä¹ ç‡
                        current_lr = scheduler.get_last_lr()[0] if hasattr(scheduler, 'get_last_lr') else optimizer.param_groups[0]['lr']

                        log_data = {
                            "train_loss": loss.item(),
                            "learning_rate": current_lr,
                            "epoch": epoch_id,
                            "step": global_step
                        }
                        swanlab.log(log_data, step=global_step)
                        print(f"SwanLab logged: step={global_step}, loss={loss.item():.4f}, lr={current_lr:.2e}")
                    except Exception as e:
                        print(f"Warning: Failed to log to SwanLab: {e}")
                elif global_step % args.logging_steps == 0:
                    print(f"Step {global_step}: main_process={accelerator.is_main_process}, swanlab_run={args.swanlab_run is not None}")

                # æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix({
                    'loss': f"{loss.item():.4f}",
                    'avg_loss': f"{epoch_loss/step_count:.4f}"
                })

                # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆåªåœ¨save_steps > 0æ—¶ä¿å­˜ï¼‰
                if save_steps > 0:
                    model_logger.on_step_end(accelerator, model, save_steps)

                # å®šæœŸæ¸…ç†æ˜¾å­˜
                if step % 10 == 0:
                    if hasattr(torch.cuda, 'empty_cache'):
                        torch.cuda.empty_cache()

        # æ¯ä¸ªepochç»“æŸæ—¶çš„å¤„ç† - æ€»æ˜¯ä¿å­˜epochæ£€æŸ¥ç‚¹
        model_logger.on_epoch_end(accelerator, model, epoch_id)

        accelerator.print(f"Epoch {epoch_id+1} completed. Average loss: {epoch_loss/step_count:.4f}")

    # è®­ç»ƒç»“æŸå¤„ç†ï¼ˆåªåœ¨save_steps > 0æ—¶ä¿å­˜æœ€åçš„stepæ£€æŸ¥ç‚¹ï¼‰
    if save_steps > 0:
        model_logger.on_training_end(accelerator, model, save_steps)

    # æœ€ç»ˆæ¸…ç†æ˜¾å­˜
    if hasattr(torch.cuda, 'empty_cache'):
        torch.cuda.empty_cache()


def create_heatmap_parser():
    """
    åˆ›å»ºçƒ­åŠ›å›¾è®­ç»ƒä¸“ç”¨çš„å‚æ•°è§£æå™¨
    """
    import argparse
    parser = argparse.ArgumentParser(description="Heatmap sequence training for Wan2.2")

    # ä»wan_parserå¤åˆ¶å¿…è¦çš„å‚æ•°
    parser.add_argument("--learning_rate", type=float, default=1e-4, help="Learning rate.")
    parser.add_argument("--num_epochs", type=int, default=5, help="Number of training epochs.")
    parser.add_argument("--output_path", type=str, required=True, help="Output path.")
    parser.add_argument("--remove_prefix_in_ckpt", type=str, default="", help="Remove prefix in checkpoint.")
    parser.add_argument("--trainable_models", type=str, default="", help="Trainable models.")
    parser.add_argument("--lora_base_model", type=str, default="", help="LoRA base model.")
    parser.add_argument("--lora_target_modules", type=str, default="q,k,v,o,ffn.0,ffn.2", help="LoRA target modules.")
    parser.add_argument("--lora_rank", type=int, default=32, help="LoRA rank.")
    parser.add_argument("--lora_checkpoint", type=str, default="", help="LoRA checkpoint.")
    parser.add_argument("--extra_inputs", type=str, default="", help="Extra inputs.")
    parser.add_argument("--use_gradient_checkpointing_offload", action="store_true", help="Use gradient checkpointing offload.")
    parser.add_argument("--gradient_accumulation_steps", type=int, default=1, help="Gradient accumulation steps.")
    parser.add_argument("--max_timestep_boundary", type=float, default=1.0, help="Max timestep boundary.")
    parser.add_argument("--min_timestep_boundary", type=float, default=0.0, help="Min timestep boundary.")
    parser.add_argument("--find_unused_parameters", action="store_true", help="Find unused parameters.")
    parser.add_argument("--save_steps", type=int, default=500, help="Save steps.")
    parser.add_argument("--dataset_num_workers", type=int, default=0, help="Dataset num workers.")
    parser.add_argument("--weight_decay", type=float, default=0.0, help="Weight decay.")
    parser.add_argument("--model_paths", type=str, default="", help="Model paths.")
    parser.add_argument("--model_id_with_origin_paths", type=str, default="", help="Model ID with origin paths.")
    parser.add_argument("--height", type=int, default=256, help="Image height.")
    parser.add_argument("--width", type=int, default=256, help="Image width.")
    parser.add_argument("--num_frames", type=int, default=5, help="Number of frames.")
    parser.add_argument("--dataset_repeat", type=int, default=1, help="Dataset repeat.")
    parser.add_argument("--train_batch_size", type=int, default=1, help="Training batch size.")
    parser.add_argument("--max_grad_norm", type=float, default=1.0, help="Max gradient norm.")
    parser.add_argument("--warmup_steps", type=int, default=0, help="Warmup steps.")
    parser.add_argument("--logging_steps", type=int, default=10, help="Logging steps.")

    # æ·»åŠ çƒ­åŠ›å›¾ä¸“ç”¨å‚æ•°
    parser.add_argument("--heatmap_data_root", type=str, required=True,
                       help="Root directory containing robot trajectory data")
    parser.add_argument("--sequence_length", type=int, default=10,
                       help="Length of heatmap sequence to predict")
    parser.add_argument("--step_interval", type=int, default=1,
                       help="Interval between trajectory steps")
    parser.add_argument("--min_trail_length", type=int, default=15,
                       help="Minimum trajectory length requirement")
    parser.add_argument("--heatmap_sigma", type=float, default=1.5,
                       help="Standard deviation for Gaussian heatmap generation")
    parser.add_argument("--colormap_name", type=str, default="viridis",
                       help="Colormap name for heatmap conversion")
    parser.add_argument("--scene_bounds", type=str,
                       default="0,-0.45,-0.05,0.8,0.55,0.6",
                       help="Scene bounds as comma-separated values")
    parser.add_argument("--transform_augmentation_xyz", type=str,
                       default="0.1,0.1,0.1",
                       help="XYZ augmentation range as comma-separated values")
    parser.add_argument("--transform_augmentation_rpy", type=str,
                       default="0.0,0.0,20.0",
                       help="RPY augmentation range as comma-separated values")
    parser.add_argument("--disable_augmentation", action="store_true",
                       help="Disable data augmentation")
    parser.add_argument("--debug_mode", action="store_true",
                       help="Enable debug mode (use fewer data)")

    # SwanLabç›¸å…³å‚æ•°
    parser.add_argument("--enable_swanlab", action="store_true",
                       help="Enable SwanLab logging")
    parser.add_argument("--swanlab_api_key", type=str, default="h1x6LOLp5qGLTfsPuB7Qw",
                       help="SwanLab API key")
    parser.add_argument("--swanlab_project", type=str, default="wan2.2-heatmap-training",
                       help="SwanLab project name")
    parser.add_argument("--swanlab_experiment", type=str, default="heatmap-lora",
                       help="SwanLab experiment name")

    return parser


def parse_float_list(s: str, name: str):
    """
    è§£æé€—å·åˆ†éš”çš„æµ®ç‚¹æ•°åˆ—è¡¨
    """
    try:
        return [float(x.strip()) for x in s.split(',')]
    except ValueError as e:
        raise ValueError(f"Invalid format for {name}: {s}. Expected comma-separated numbers.") from e


if __name__ == "__main__":
    parser = create_heatmap_parser()
    args = parser.parse_args()

    print("="*60)
    print("HEATMAP SEQUENCE TRAINING FOR WAN2.2")
    print("="*60)
    print(f"Data root: {args.heatmap_data_root}")
    print(f"Sequence length: {args.sequence_length}")
    print(f"Colormap: {args.colormap_name}")
    print(f"Output path: {args.output_path}")
    print(f"Debug mode: {args.debug_mode}")
    print(f"SwanLab enabled: {args.enable_swanlab and not args.debug_mode}")
    print("="*60)

    # åˆå§‹åŒ–SwanLabï¼ˆåªåœ¨ä¸»è¿›ç¨‹è¿›è¡Œï¼‰
    swanlab_run = None

    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„acceleratoræ¥æ£€æŸ¥æ˜¯å¦ä¸ºä¸»è¿›ç¨‹
    temp_accelerator = Accelerator()
    is_main_process = temp_accelerator.is_main_process

    if is_main_process and args.enable_swanlab and not args.debug_mode and SWANLAB_AVAILABLE:
        try:
            print("Initializing SwanLab...")
            print(f"API Key: {args.swanlab_api_key[:8]}***")
            print(f"Project: {args.swanlab_project}")
            print(f"Experiment: {args.swanlab_experiment}")

            swanlab.login(api_key=args.swanlab_api_key)
            swanlab_run = swanlab.init(
                project=args.swanlab_project,
                experiment_name=args.swanlab_experiment,
                config={
                    "learning_rate": args.learning_rate,
                    "num_epochs": args.num_epochs,
                    "sequence_length": args.sequence_length,
                    "train_batch_size": args.train_batch_size,
                    "lora_rank": args.lora_rank,
                    "heatmap_sigma": args.heatmap_sigma,
                    "colormap_name": args.colormap_name,
                    "height": args.height,
                    "width": args.width,
                    "gradient_accumulation_steps": args.gradient_accumulation_steps,
                    "logging_steps": args.logging_steps,
                }
            )
            print(f"âœ… SwanLab initialized successfully!")
            print(f"   Project: {args.swanlab_project}")
            print(f"   Experiment: {args.swanlab_experiment}")
            print(f"   Logging frequency: every {args.logging_steps} steps")

            # æµ‹è¯•ä¸€æ¬¡æ—¥å¿—è®°å½•
            swanlab.log({"test": 1.0}, step=0)
            print("âœ… Test log sent to SwanLab")

        except Exception as e:
            print(f"âŒ Failed to initialize SwanLab: {e}")
            import traceback
            traceback.print_exc()
            swanlab_run = None
    elif is_main_process and args.enable_swanlab and args.debug_mode:
        print("SwanLab disabled in debug mode")
    elif is_main_process and args.enable_swanlab and not SWANLAB_AVAILABLE:
        print("Warning: SwanLab requested but not available. Install with: pip install swanlab")

    # è§£æå‚æ•°
    scene_bounds = parse_float_list(args.scene_bounds, "scene_bounds")
    transform_augmentation_xyz = parse_float_list(args.transform_augmentation_xyz, "transform_augmentation_xyz")
    transform_augmentation_rpy = parse_float_list(args.transform_augmentation_rpy, "transform_augmentation_rpy")

    # åˆ›å»ºçƒ­åŠ›å›¾æ•°æ®é›†
    if is_main_process:
        print("Creating heatmap dataset...")
    try:
        dataset = HeatmapDatasetFactory.create_robot_trajectory_dataset(
            data_root=args.heatmap_data_root,
            sequence_length=args.sequence_length,
            step_interval=args.step_interval,
            min_trail_length=args.min_trail_length,
            image_size=(args.height, args.width),
            sigma=args.heatmap_sigma,
            augmentation=not args.disable_augmentation,
            mode="train",
            scene_bounds=scene_bounds,
            transform_augmentation_xyz=transform_augmentation_xyz,
            transform_augmentation_rpy=transform_augmentation_rpy,
            debug=args.debug_mode,
            colormap_name=args.colormap_name,
            repeat=args.dataset_repeat
        )
        if is_main_process:
            print(f"Dataset created successfully with {len(dataset)} samples")

            # æµ‹è¯•æ•°æ®åŠ è½½
            print("Testing data loading...")
            test_sample = dataset[0]
            print(f"Sample keys: {list(test_sample.keys())}")
            print(f"Video frames: {len(test_sample['video'])}")
            print(f"First frame size: {test_sample['video'][0].size}")
            print(f"Prompt: {test_sample['prompt'][:50]}...")

    except Exception as e:
        if is_main_process:
            print(f"Error creating dataset: {e}")
            import traceback
            traceback.print_exc()
        exit(1)

    # åˆ›å»ºè®­ç»ƒæ¨¡å—
    if is_main_process:
        print("Creating training module...")
    try:
        # å¤„ç†ç©ºå­—ç¬¦ä¸²å‚æ•°ï¼Œé¿å…å¯¼è‡´é”™è¯¯
        model_id_with_origin_paths = args.model_id_with_origin_paths if args.model_id_with_origin_paths else None
        lora_checkpoint = args.lora_checkpoint if args.lora_checkpoint else None
        trainable_models = args.trainable_models if args.trainable_models else None

        model = HeatmapWanTrainingModule(
            model_paths=args.model_paths,
            model_id_with_origin_paths=model_id_with_origin_paths,
            trainable_models=trainable_models,
            lora_base_model=args.lora_base_model,
            lora_target_modules=args.lora_target_modules,
            lora_rank=args.lora_rank,
            lora_checkpoint=lora_checkpoint,
            use_gradient_checkpointing_offload=args.use_gradient_checkpointing_offload,
            extra_inputs=args.extra_inputs,
            max_timestep_boundary=args.max_timestep_boundary,
            min_timestep_boundary=args.min_timestep_boundary,
        )
        if is_main_process:
            print("Training module created successfully")

    except Exception as e:
        if is_main_process:
            print(f"Error creating training module: {e}")
            import traceback
            traceback.print_exc()
        exit(1)

    # åˆ›å»ºæ¨¡å‹æ—¥å¿—å™¨
    if is_main_process:
        print("Setting up model logger...")
    model_logger = ModelLogger(
        args.output_path,
        remove_prefix_in_ckpt=args.remove_prefix_in_ckpt
    )

    # å¯åŠ¨è®­ç»ƒ
    if is_main_process:
        print("Starting training...")
        print(f"Optimizing data loading with {args.dataset_num_workers} workers...")
    try:
        # å¦‚æœSwanLabå¯ç”¨ï¼Œæ·»åŠ åˆ°argsä¸­
        if swanlab_run is not None:
            args.swanlab_run = swanlab_run
        else:
            args.swanlab_run = None

        # ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬çš„è®­ç»ƒå‡½æ•°ï¼Œä¸“é—¨é’ˆå¯¹40GB A100ä¼˜åŒ–
        launch_optimized_training_task(dataset, model, model_logger, args=args, temp_accelerator=temp_accelerator)

        if is_main_process:
            print("Training completed successfully!")

        # ç»“æŸSwanLabå®éªŒ
        if swanlab_run is not None:
            swanlab_run.finish()
            if is_main_process:
                print("SwanLab experiment finished")

    except Exception as e:
        if is_main_process:
            print(f"Training failed: {e}")
            import traceback
            traceback.print_exc()

        # ç¡®ä¿SwanLabå®éªŒæ­£ç¡®ç»“æŸ
        if swanlab_run is not None:
            swanlab_run.finish()

        exit(1)